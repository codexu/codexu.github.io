import{_ as a,c as t,o,ae as r}from"./chunks/framework.Dgg8-8ov.js";const m=JSON.parse('{"title":"AI 配置","description":"","frontmatter":{},"headers":[],"relativePath":"zh/settings/model-config.md","filePath":"zh/settings/model-config.md"}'),i={name:"zh/settings/model-config.md"};function l(p,e,d,n,s,h){return o(),t("div",null,e[0]||(e[0]=[r('<h1 id="ai-配置" tabindex="-1">AI 配置 <a class="header-anchor" href="#ai-配置" aria-label="Permalink to &quot;AI 配置&quot;">​</a></h1><p>NoteGen 集成了主流的 AI 模型服务，还支持自定义配置，以满足不同的需求。</p><p><img src="https://s2.loli.net/2025/05/26/S9C58QMryevcbJA.png" alt="1.png"></p><h2 id="配置" tabindex="-1">配置 <a class="header-anchor" href="#配置" aria-label="Permalink to &quot;配置&quot;">​</a></h2><h3 id="model-provider" tabindex="-1">Model Provider <a class="header-anchor" href="#model-provider" aria-label="Permalink to &quot;Model Provider&quot;">​</a></h3><p>这里是选择模型提供商，如果不存在你所使用的服务商，请点击旁边的<code>+ 自定义</code>， 创建新的配置。</p><p>点击复制，则可以将相同配置进行复制，用于同一服务商下使用不同模型。</p><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>Ollama、LM Studio 等本地搭建的模型，如果配之后无法正常使用，请查看是否开启了允许跨域访问。</p></div><h3 id="baseurl" tabindex="-1">BaseURL <a class="header-anchor" href="#baseurl" aria-label="Permalink to &quot;BaseURL&quot;">​</a></h3><p>这里注意，你只需要配置到版本号即可，例如：<a href="https://api.openai.com/v1%EF%BC%8C%E5%90%8E%E7%BC%80%E4%BC%9A%E8%87%AA%E5%8A%A8%E6%B7%BB%E5%8A%A0%EF%BC%8C%E5%85%B6%E4%BB%96%E5%8E%82%E5%95%86%E4%B9%9F%E6%98%AF%E5%A6%82%E6%AD%A4%EF%BC%8C%E8%AF%B7%E4%B8%8D%E8%A6%81%E5%B0%86" target="_blank" rel="noreferrer">https://api.openai.com/v1，后缀会自动添加，其他厂商也是如此，请不要将</a> <code>chat/completions</code> 填入。</p><h3 id="api-key" tabindex="-1">API Key <a class="header-anchor" href="#api-key" aria-label="Permalink to &quot;API Key&quot;">​</a></h3><p>这里填入你的对应的密钥，如果是 Ollama、LM Studio 等，可以随意填入。</p><h3 id="model" tabindex="-1">Model <a class="header-anchor" href="#model" aria-label="Permalink to &quot;Model&quot;">​</a></h3><p>一般情况下，BaseURL 和 API Key 配置正确后，Model 会自动获取，以下拉列表呈现，如果获取不到，可以手动填入。</p><h3 id="模型类型" tabindex="-1">模型类型 <a class="header-anchor" href="#模型类型" aria-label="Permalink to &quot;模型类型&quot;">​</a></h3><p>选择模型类型，用于区分不同的模型，选择错误模型类型，可能导致无法正常使用。</p><h3 id="temperature" tabindex="-1">Temperature <a class="header-anchor" href="#temperature" aria-label="Permalink to &quot;Temperature&quot;">​</a></h3><p>使用什么采样温度，介于 0 和 2 之间。较高的值（如 0.8）将使输出更加随机，而较低的值（如 0.2）将使输出更加集中和确定。 我们通常建议改变这个或top_p但不是两者。</p><h3 id="top-p" tabindex="-1">Top P <a class="header-anchor" href="#top-p" aria-label="Permalink to &quot;Top P&quot;">​</a></h3><p>一种替代温度采样的方法，称为核采样，其中模型考虑具有 top_p 概率质量的标记的结果。所以 0.1 意味着只考虑构成前 10% 概率质量的标记。 我们通常建议改变这个或temperature但不是两者。</p>',20)]))}const u=a(i,[["render",l]]);export{m as __pageData,u as default};
